

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/imgs/apple-touch-icon.png">
  <link rel="icon" href="/imgs/web-app-manifest-192x192.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="logicff">
  <meta name="keywords" content="">
  
    <meta name="description" content="由于毕设需要，且没怎么学习过AI这块，所以浅浅记录一下，但不会像之前记录MIT6.5840那样在实现细节上一笔带过。原因的话，对于分布式这块，好歹我有过一点分布式系统的经验以及一些知识，但AI这块，我仅仅之前半途而废地上过一点网课…  开始之前 根据个人经验，在开始作业之前，最好是先学习课程知识和相关的Python知识（如果没有的话），这样做作业会更加高效。 课程知识的话，首先是官网以及Yout">
<meta property="og:type" content="article">
<meta property="og:title" content="CS231n：Assignment1">
<meta property="og:url" content="https://logicff.github.io/2025/11/14/cs231n-1/">
<meta property="og:site_name" content="logicff">
<meta property="og:description" content="由于毕设需要，且没怎么学习过AI这块，所以浅浅记录一下，但不会像之前记录MIT6.5840那样在实现细节上一笔带过。原因的话，对于分布式这块，好歹我有过一点分布式系统的经验以及一些知识，但AI这块，我仅仅之前半途而废地上过一点网课…  开始之前 根据个人经验，在开始作业之前，最好是先学习课程知识和相关的Python知识（如果没有的话），这样做作业会更加高效。 课程知识的话，首先是官网以及Yout">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://logicff.github.io/images/cs231n/cs231n.png">
<meta property="article:published_time" content="2025-11-14T12:33:27.000Z">
<meta property="article:modified_time" content="2025-11-14T12:33:27.000Z">
<meta property="article:author" content="logicff">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://logicff.github.io/images/cs231n/cs231n.png">
  
  
  
  <title>CS231n：Assignment1 - logicff</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"logicff.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/imgs/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="logicff" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>logicff</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/atom.xml" target="_self">
                <i class="iconfont icon-rss"></i>
                <span>RSS</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/imgs/banner.gif') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CS231n：Assignment1"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        logicff
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-11-14 20:33" pubdate>
          2025年11月14日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          2.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          22 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CS231n：Assignment1</h1>
            
            
              <div class="markdown-body">
                
                <blockquote>
<p>由于毕设需要，且没怎么学习过AI这块，所以浅浅记录一下，但不会像之前记录MIT6.5840那样在实现细节上一笔带过。原因的话，对于分布式这块，好歹我有过一点分布式系统的经验以及一些知识，但AI这块，我仅仅之前半途而废地上过一点网课…</p>
</blockquote>
<h2 id="开始之前">开始之前</h2>
<p>根据个人经验，在开始作业之前，最好是先学习课程知识和相关的Python知识（如果没有的话），这样做作业会更加高效。</p>
<p>课程知识的话，首先是<a target="_blank" rel="noopener" href="https://cs231n.stanford.edu">官网</a>以及Youtube上的公开视频，B站上也会有人发。</p>
<p>相关的Python知识，在官网Schedule的2025/04/04<a target="_blank" rel="noopener" href="https://cs231n.github.io/python-numpy-tutorial/">Tutorial</a>中，也可以在<a target="_blank" rel="noopener" href="https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb">Colab</a>学习。最好在做作业1之前学习一下，不然对小白来说，很可能会像我一样，即使有Python基础，做个作业被Numpy什么的搞得一头雾水（比如知道该怎么实现，但一些Numpy的方法或者原理不清楚）。</p>
<p>作业的一些细节都能在官网找到，这里就不赘述了。</p>
<p>顺便分享一下我的仓库：<a target="_blank" rel="noopener" href="https://github.com/logicff/cs231n">https://github.com/logicff/cs231n</a></p>
<h2 id="q1-k-nearest-neighbor-classifier">Q1: k-Nearest Neighbor classifier</h2>
<p>这部分将在<strong>knn.ipynb</strong>中实现一个kNN图像分类器。</p>
<p>kNN分类器由两个阶段组成：</p>
<ul>
<li>在训练阶段，分类器获取训练数据并直接存储</li>
<li>在测试阶段，kNN对每个测试图像进行分类时，会将其与所有训练图像进行对比，然后采用k个最相似训练样本的标签中出现次数最多的标签作为该测试图像的标签</li>
<li>k值通过交叉验证确定</li>
</ul>
<h3 id="数据加载处理和训练阶段">数据加载、处理和训练阶段</h3>
<p>运行完初始化单元格后，导入数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Load the raw CIFAR-10 data.</span><br>cifar10_dir = <span class="hljs-string">&#x27;cs231n/datasets/cifar-10-batches-py&#x27;</span><br><br><span class="hljs-comment"># Cleaning up variables to prevent loading data multiple times (which may cause memory issue)</span><br><span class="hljs-keyword">try</span>:<br>   <span class="hljs-keyword">del</span> X_train, y_train<br>   <span class="hljs-keyword">del</span> X_test, y_test<br>   <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Clear previously loaded data.&#x27;</span>)<br><span class="hljs-keyword">except</span>:<br>   <span class="hljs-keyword">pass</span><br><br>X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)<br><br><span class="hljs-comment"># As a sanity check, we print out the size of the training and test data.</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Training data shape: &#x27;</span>, X_train.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Training labels shape: &#x27;</span>, y_train.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Test data shape: &#x27;</span>, X_test.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Test labels shape: &#x27;</span>, y_test.shape)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># Training data shape:  (50000, 32, 32, 3)</span><br><span class="hljs-comment"># Training labels shape:  (50000,)</span><br><span class="hljs-comment"># Test data shape:  (10000, 32, 32, 3)</span><br><span class="hljs-comment"># Test labels shape:  (10000,)</span><br></code></pre></td></tr></table></figure>
<p>展示一些训练数据样本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Visualize some examples from the dataset.</span><br><span class="hljs-comment"># We show a few examples of training images from each class.</span><br>classes = [<span class="hljs-string">&#x27;plane&#x27;</span>, <span class="hljs-string">&#x27;car&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;deer&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;frog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;ship&#x27;</span>, <span class="hljs-string">&#x27;truck&#x27;</span>]<br>num_classes = <span class="hljs-built_in">len</span>(classes)<br>samples_per_class = <span class="hljs-number">7</span><br><span class="hljs-keyword">for</span> y, cls <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(classes):<br>    idxs = np.flatnonzero(y_train == y)<br>    idxs = np.random.choice(idxs, samples_per_class, replace=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">for</span> i, idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(idxs):<br>        plt_idx = i * num_classes + y + <span class="hljs-number">1</span><br>        plt.subplot(samples_per_class, num_classes, plt_idx)<br>        plt.imshow(X_train[idx].astype(<span class="hljs-string">&#x27;uint8&#x27;</span>))<br>        plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>            plt.title(cls)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p>为了测试效率，仅取训练集前5000个作为当前训练集，取测试集前500个作为当前测试集，并将图像展平为一个行向量，展平后的列数为32×32×3=3072列。：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Subsample the data for more efficient code execution in this exercise</span><br>num_training = <span class="hljs-number">5000</span><br>mask = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(num_training))<br>X_train = X_train[mask]<br>y_train = y_train[mask]<br><br>num_test = <span class="hljs-number">500</span><br>mask = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(num_test))<br>X_test = X_test[mask]<br>y_test = y_test[mask]<br><br><span class="hljs-comment"># Reshape the image data into rows</span><br>X_train = np.reshape(X_train, (X_train.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>))<br>X_test = np.reshape(X_test, (X_test.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(X_train.shape, X_test.shape)<br><br><span class="hljs-comment"># Output</span><br><span class="hljs-comment"># (5000, 3072) (500, 3072)</span><br></code></pre></td></tr></table></figure>
<p>导入kNN分类器，并存储训练数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> cs231n.classifiers <span class="hljs-keyword">import</span> KNearestNeighbor<br><br><span class="hljs-comment"># Create a kNN classifier instance.</span><br><span class="hljs-comment"># Remember that training a kNN classifier is a noop:</span><br><span class="hljs-comment"># the Classifier simply remembers the data and does no further processing</span><br>classifier = KNearestNeighbor()<br>classifier.train(X_train, y_train)<br></code></pre></td></tr></table></figure>
<h3 id="测试阶段">测试阶段</h3>
<p>计算每张测试图片与每张训练图片的距离：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Open cs231n/classifiers/k_nearest_neighbor.py and implement</span><br><span class="hljs-comment"># compute_distances_two_loops.</span><br><br><span class="hljs-comment"># Test your implementation:</span><br>dists = classifier.compute_distances_two_loops(X_test)<br><span class="hljs-built_in">print</span>(dists.shape)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># (500, 5000)</span><br></code></pre></td></tr></table></figure>
<p>在<code>cs231n/classifiers/k_nearest_neighbor.py</code>中实现<code>compute_distances_two_loops</code>，直接套公式即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># In cs231n/classifiers/k_nearest_neighbor.py</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_distances_two_loops</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Compute the distance between each test point in X and each training point</span><br><span class="hljs-string">        in self.X_train using a nested loop over both the training data and the</span><br><span class="hljs-string">        test data.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Inputs:</span><br><span class="hljs-string">        - X: A numpy array of shape (num_test, D) containing test data.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">        - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span><br><span class="hljs-string">          is the Euclidean distance between the ith test point and the jth training</span><br><span class="hljs-string">          point.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        num_test = X.shape[<span class="hljs-number">0</span>]<br>        num_train = <span class="hljs-variable language_">self</span>.X_train.shape[<span class="hljs-number">0</span>]<br>        dists = np.zeros((num_test, num_train))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_test):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train):<br>                <span class="hljs-comment">#####################################################################</span><br>                <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span>                                                             #</span><br>                <span class="hljs-comment"># Compute the l2 distance between the ith test point and the jth    #</span><br>                <span class="hljs-comment"># training point, and store the result in dists[i, j]. You should   #</span><br>                <span class="hljs-comment"># not use a loop over dimension, nor use np.linalg.norm().          #</span><br>                <span class="hljs-comment">#####################################################################</span><br>                <span class="hljs-comment"># L2 distance: d2(I1, I2) = \sqrt&#123;\sum&#123;\square&#123;I^p_1 - I^p_2&#125;&#125;&#125;</span><br>                dists[i, j] = np.sqrt(np.<span class="hljs-built_in">sum</span>(np.square(X[i] - <span class="hljs-variable language_">self</span>.X_train[j])))<br>        <span class="hljs-keyword">return</span> dists<br></code></pre></td></tr></table></figure>
<p>回到knn.ipynb，可视化得到的<code>dists</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># We can visualize the distance matrix: each row is a single test example and</span><br><span class="hljs-comment"># its distances to training examples</span><br>plt.imshow(dists, interpolation=<span class="hljs-string">&#x27;none&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>
<figure>
<img src="/images/cs231n/dists-visual.png" srcset="/imgs/loading.gif" lazyload alt="visualized distance matrix" /><figcaption>visualized distance matrix</figcaption>
</figure>
<p><strong>Inline Question 1</strong></p>
<p>Notice the structured patterns in the distance matrix, where some rows or columns are visibly brighter. (Note that with the default color scheme black indicates low distances while white indicates high distances.)</p>
<ul>
<li>What in the data is the cause behind the distinctly bright rows?</li>
<li>What causes the columns?</li>
</ul>
<p><span class="math inline">$\color{blue}{\textit Your Answer:}$</span></p>
<ul>
<li><p>Bright rows correspond to test samples that are dissimilar to all training samples. This happens because these test samples may be have high noise, or belong to classes with weak representation in the training set—leading to large distances to all stored training samples.</p></li>
<li><p>Bright columns correspond to training samples that are dissimilar to all test samples.</p></li>
</ul>
<p>第二个任务点，预测标签，输入一个距离矩阵，和最近邻居数量k，输出测试集的预测标签。先在<code>cs231n/classifiers/k_nearest_neighbor.py</code>中实现<code>predict_labels</code>，按照注释中的提示做即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># In cs231n/classifiers/k_nearest_neighbor.py</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_labels</span>(<span class="hljs-params">self, dists, k=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Given a matrix of distances between test points and training points,</span><br><span class="hljs-string">        predict a label for each test point.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Inputs:</span><br><span class="hljs-string">        - dists: A numpy array of shape (num_test, num_train) where dists[i, j]</span><br><span class="hljs-string">          gives the distance betwen the ith test point and the jth training point.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">        - y: A numpy array of shape (num_test,) containing predicted labels for the</span><br><span class="hljs-string">          test data, where y[i] is the predicted label for the test point X[i].</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        num_test = dists.shape[<span class="hljs-number">0</span>]<br>        y_pred = np.zeros(num_test)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_test):<br>            <span class="hljs-comment"># A list of length k storing the labels of the k nearest neighbors to</span><br>            <span class="hljs-comment"># the ith test point.</span><br>            closest_y = []<br>            <span class="hljs-comment">#########################################################################</span><br>            <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span>                                                                 #</span><br>            <span class="hljs-comment"># Use the distance matrix to find the k nearest neighbors of the ith    #</span><br>            <span class="hljs-comment"># testing point, and use self.y_train to find the labels of these       #</span><br>            <span class="hljs-comment"># neighbors. Store these labels in closest_y.                           #</span><br>            <span class="hljs-comment"># Hint: Look up the function numpy.argsort.                             #</span><br>            <span class="hljs-comment">#########################################################################</span><br>            k_nearest_idxs = np.argsort(dists[i])[:k]<br>            closest_y = <span class="hljs-variable language_">self</span>.y_train[k_nearest_idxs]<br><br><br>            <span class="hljs-comment">#########################################################################</span><br>            <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span>                                                                 #</span><br>            <span class="hljs-comment"># Now that you have found the labels of the k nearest neighbors, you    #</span><br>            <span class="hljs-comment"># need to find the most common label in the list closest_y of labels.   #</span><br>            <span class="hljs-comment"># Store this label in y_pred[i]. Break ties by choosing the smaller     #</span><br>            <span class="hljs-comment"># label.                                                                #</span><br>            <span class="hljs-comment">#########################################################################</span><br>            counts = np.bincount(closest_y)<br>            y_pred[i] = np.argmax(counts)<br><br><br>        <span class="hljs-keyword">return</span> y_pred<br></code></pre></td></tr></table></figure>
<p>使用k=1进行预测，查看预测准确率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Now implement the function predict_labels and run the code below:</span><br><span class="hljs-comment"># We use k = 1 (which is Nearest Neighbor).</span><br>y_test_pred = classifier.predict_labels(dists, k=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Compute and print the fraction of correctly predicted examples</span><br>num_correct = np.<span class="hljs-built_in">sum</span>(y_test_pred == y_test)<br>accuracy = <span class="hljs-built_in">float</span>(num_correct) / num_test<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Got %d / %d correct =&gt; accuracy: %f&#x27;</span> % (num_correct, num_test, accuracy))<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># Got 137 / 500 correct =&gt; accuracy: 0.274000</span><br></code></pre></td></tr></table></figure>
<p>再试试k=5：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">y_test_pred = classifier.predict_labels(dists, k=<span class="hljs-number">5</span>)<br>num_correct = np.<span class="hljs-built_in">sum</span>(y_test_pred == y_test)<br>accuracy = <span class="hljs-built_in">float</span>(num_correct) / num_test<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Got %d / %d correct =&gt; accuracy: %f&#x27;</span> % (num_correct, num_test, accuracy))<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># Got 139 / 500 correct =&gt; accuracy: 0.278000</span><br></code></pre></td></tr></table></figure>
<p>可以看到k=5的表现要比k=1稍微好一点。</p>
<p><strong>Inline Question 2</strong></p>
<p>We can also use other distance metrics such as L1 distance. For pixel values <span class="math inline"><em>p</em><sub><em>i</em><em>j</em></sub><sup>(<em>k</em>)</sup></span> at location <span class="math inline">(<em>i</em>, <em>j</em>)</span> of some image <span class="math inline"><em>I</em><sub><em>k</em></sub></span>,</p>
<p>the mean <span class="math inline"><em>μ</em></span> across all pixels over all images is <br /><span class="math display">$$\mu=\frac{1}{nhw}\sum_{k=1}^n\sum_{i=1}^{h}\sum_{j=1}^{w}p_{ij}^{(k)}$$</span><br /> And the pixel-wise mean <span class="math inline"><em>μ</em><sub><em>i</em><em>j</em></sub></span> across all images is <br /><span class="math display">$$\mu_{ij}=\frac{1}{n}\sum_{k=1}^np_{ij}^{(k)}.$$</span><br /> The general standard deviation <span class="math inline"><em>σ</em></span> and pixel-wise standard deviation <span class="math inline"><em>σ</em><sub><em>i</em><em>j</em></sub></span> is defined similarly.</p>
<p>Which of the following preprocessing steps will not change the performance of a Nearest Neighbor classifier that uses L1 distance? Select all that apply. To clarify, both training and test examples are preprocessed in the same way.</p>
<ol type="1">
<li>Subtracting the mean <span class="math inline"><em>μ</em></span> (<span class="math inline"><em>p̃</em><sub><em>i</em><em>j</em></sub><sup>(<em>k</em>)</sup> = <em>p</em><sub><em>i</em><em>j</em></sub><sup>(<em>k</em>)</sup> − <em>μ</em></span>.)</li>
<li>Subtracting the per pixel mean <span class="math inline"><em>μ</em><sub><em>i</em><em>j</em></sub></span> (<span class="math inline"><em>p̃</em><sub><em>i</em><em>j</em></sub><sup>(<em>k</em>)</sup> = <em>p</em><sub><em>i</em><em>j</em></sub><sup>(<em>k</em>)</sup> − <em>μ</em><sub><em>i</em><em>j</em></sub></span>.)</li>
<li>Subtracting the mean <span class="math inline"><em>μ</em></span> and dividing by the standard deviation <span class="math inline"><em>σ</em></span>.</li>
<li>Subtracting the pixel-wise mean <span class="math inline"><em>μ</em><sub><em>i</em><em>j</em></sub></span> and dividing by the pixel-wise standard deviation <span class="math inline"><em>σ</em><sub><em>i</em><em>j</em></sub></span>.</li>
<li>Rotating the coordinate axes of the data, which means rotating all the images by the same angle. Empty regions in the image caused by rotation are padded with a same pixel value and no interpolation is performed.</li>
</ol>
<p><span class="math inline">$\color{blue}{\textit Your Answer:}$</span> 1, 2, 3, 5</p>
<p><span class="math inline">$\color{blue}{\textit Your Explanation:}$</span> The core principle is that preprocessing must preserve the relative magnitudes of L1 distances between samples. Only 4 breaks it.</p>
<p>现在尝试在一个循环内完成<code>dists</code>的计算，即每次循环直接计算一个测试图像与所有训练图像的距离，可以利用Numpy的广播机制（开始提到的<a target="_blank" rel="noopener" href="https://cs231n.github.io/python-numpy-tutorial/">Tutorial</a>中有讲）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># In cs231n/classifiers/k_nearest_neighbor.py</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_distances_one_loop</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Compute the distance between each test point in X and each training point</span><br><span class="hljs-string">        in self.X_train using a single loop over the test data.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Input / Output: Same as compute_distances_two_loops</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        num_test = X.shape[<span class="hljs-number">0</span>]<br>        num_train = <span class="hljs-variable language_">self</span>.X_train.shape[<span class="hljs-number">0</span>]<br>        dists = np.zeros((num_test, num_train))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_test):<br>            <span class="hljs-comment">#######################################################################</span><br>            <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span>                                                               #</span><br>            <span class="hljs-comment"># Compute the l2 distance between the ith test point and all training #</span><br>            <span class="hljs-comment"># points, and store the result in dists[i, :].                        #</span><br>            <span class="hljs-comment"># Do not use np.linalg.norm().                                        #</span><br>            <span class="hljs-comment">#######################################################################</span><br>            dists[i] = np.sqrt(np.<span class="hljs-built_in">sum</span>(np.square(X[i] - <span class="hljs-variable language_">self</span>.X_train), axis=<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">return</span> dists<br></code></pre></td></tr></table></figure>
<p>测试并检查正确性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Now lets speed up distance matrix computation by using partial vectorization</span><br><span class="hljs-comment"># with one loop. Implement the function compute_distances_one_loop and run the</span><br><span class="hljs-comment"># code below:</span><br>dists_one = classifier.compute_distances_one_loop(X_test)<br><br><span class="hljs-comment"># To ensure that our vectorized implementation is correct, we make sure that it</span><br><span class="hljs-comment"># agrees with the naive implementation. There are many ways to decide whether</span><br><span class="hljs-comment"># two matrices are similar; one of the simplest is the Frobenius norm. In case</span><br><span class="hljs-comment"># you haven&#x27;t seen it before, the Frobenius norm of two matrices is the square</span><br><span class="hljs-comment"># root of the squared sum of differences of all elements; in other words, reshape</span><br><span class="hljs-comment"># the matrices into vectors and compute the Euclidean distance between them.</span><br>difference = np.linalg.norm(dists - dists_one, <span class="hljs-built_in">ord</span>=<span class="hljs-string">&#x27;fro&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;One loop difference was: %f&#x27;</span> % (difference, ))<br><span class="hljs-keyword">if</span> difference &lt; <span class="hljs-number">0.001</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Good! The distance matrices are the same&#x27;</span>)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Uh-oh! The distance matrices are different&#x27;</span>)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># One loop difference was: 0.000000</span><br><span class="hljs-comment"># Good! The distance matrices are the same</span><br></code></pre></td></tr></table></figure>
<p>接下来，再尝试无循环计算<code>dists</code>，这次要和之前的two_loop、one_loop有本质上的不同。</p>
<p>尽管one_loop借助了Numpy的广播机制，但在计算量和计算效率上和two_loop差别不大，可以说one_loop和two_loop没有本质上的差别。</p>
<p>首先，我们看距离公式： <br /><span class="math display"><em>D</em><sub><em>i</em>, <em>j</em></sub> = (<em>t</em><em>e</em><em>s</em><em>t</em><sub><em>i</em></sub> − <em>t</em><em>r</em><em>a</em><em>i</em><em>n</em><sub><em>j</em></sub>)<sup>2</sup> = <em>t</em><em>e</em><em>s</em><em>t</em><sub><em>i</em></sub><sup>2</sup> + <em>t</em><em>r</em><em>a</em><em>i</em><em>n</em><sub><em>j</em></sub><sup>2</sup> − 2<em>t</em><em>e</em><em>s</em><em>t</em><sub><em>i</em></sub> * <em>t</em><em>r</em><em>a</em><em>i</em><em>n</em><sub><em>j</em></sub></span><br /> 展开之前，想要不用循环的话，可以借助Numpy的广播机制，如<code>dists = np.sqrt(np.sum(np.square(X[:, np.newaxis, :] - self.X_train), axis=2))</code>，或者<code>dists = np.sqrt(np.sum(np.square(X[:, np.newaxis, :] - self.X_train[np.newaxis, :, :]), axis=2))</code>，但是这个方法，一是和之前的one_loop和two_loop没有本质上的差别（除非有底层优化），二是内存占用也是相当大的（拿作业的数据来说，<code>X[:, np.newaxis, :] - self.X_train[np.newaxis, :, :]</code>将得到一个包含num_test×num_train×3072个元素的大数组/矩阵）。</p>
<p>展开之后，两个平方项可以不用多次计算，分别计算后保存，后续复用这些结果即可，有点像动态规划的思想，而展开前的平方项由于同时依赖test_i和train_j，就没法这么做了。除此之外，test_i * train_j则可借助矩阵乘法实现，虽然计算量没变，但矩阵乘法是有底层优化的，运行速度很快。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># In cs231n/classifiers/k_nearest_neighbor.py</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_distances_no_loops</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Compute the distance between each test point in X and each training point</span><br><span class="hljs-string">        in self.X_train using no explicit loops.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Input / Output: Same as compute_distances_two_loops</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        num_test = X.shape[<span class="hljs-number">0</span>]<br>        num_train = <span class="hljs-variable language_">self</span>.X_train.shape[<span class="hljs-number">0</span>]<br>        dists = np.zeros((num_test, num_train))<br>        <span class="hljs-comment">#########################################################################</span><br>        <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span>                                                                 #</span><br>        <span class="hljs-comment"># Compute the l2 distance between all test points and all training      #</span><br>        <span class="hljs-comment"># points without using any explicit loops, and store the result in      #</span><br>        <span class="hljs-comment"># dists.                                                                #</span><br>        <span class="hljs-comment">#                                                                       #</span><br>        <span class="hljs-comment"># You should implement this function using only basic array operations; #</span><br>        <span class="hljs-comment"># in particular you should not use functions from scipy,                #</span><br>        <span class="hljs-comment"># nor use np.linalg.norm().                                             #</span><br>        <span class="hljs-comment">#                                                                       #</span><br>        <span class="hljs-comment"># HINT: Try to formulate the l2 distance using matrix multiplication    #</span><br>        <span class="hljs-comment">#       and two broadcast sums.                                         #</span><br>        <span class="hljs-comment">#########################################################################</span><br>        sum_x2 = np.reshape(np.<span class="hljs-built_in">sum</span>(np.square(X), axis=<span class="hljs-number">1</span>), (num_test, <span class="hljs-number">1</span>))<br>        sum_xt2 = np.reshape(np.<span class="hljs-built_in">sum</span>(np.square(<span class="hljs-variable language_">self</span>.X_train), axis=<span class="hljs-number">1</span>), (<span class="hljs-number">1</span>, num_train))<br>        matmul_xxt = np.dot(X, <span class="hljs-variable language_">self</span>.X_train.T)<br>        dists = np.sqrt(sum_x2 + sum_xt2 - <span class="hljs-number">2</span> * matmul_xxt)<br>        <span class="hljs-keyword">return</span> dists<br></code></pre></td></tr></table></figure>
<p>测试并检查正确性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Now implement the fully vectorized version inside compute_distances_no_loops</span><br><span class="hljs-comment"># and run the code</span><br>dists_two = classifier.compute_distances_no_loops(X_test)<br><br><span class="hljs-comment"># check that the distance matrix agrees with the one we computed before:</span><br>difference = np.linalg.norm(dists - dists_two, <span class="hljs-built_in">ord</span>=<span class="hljs-string">&#x27;fro&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;No loop difference was: %f&#x27;</span> % (difference, ))<br><span class="hljs-keyword">if</span> difference &lt; <span class="hljs-number">0.001</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Good! The distance matrices are the same&#x27;</span>)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Uh-oh! The distance matrices are different&#x27;</span>)<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># No loop difference was: 0.000000</span><br><span class="hljs-comment"># Good! The distance matrices are the same</span><br></code></pre></td></tr></table></figure>
<p>三种方法的运行时间对比：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Let&#x27;s compare how fast the implementations are</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">time_function</span>(<span class="hljs-params">f, *args</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Call a function f with args and return the time (in seconds) that it took to execute.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">import</span> time<br>    tic = time.time()<br>    f(*args)<br>    toc = time.time()<br>    <span class="hljs-keyword">return</span> toc - tic<br><br>two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Two loop version took %f seconds&#x27;</span> % two_loop_time)<br><br>one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;One loop version took %f seconds&#x27;</span> % one_loop_time)<br><br>no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;No loop version took %f seconds&#x27;</span> % no_loop_time)<br><br><span class="hljs-comment"># You should see significantly faster performance with the fully vectorized implementation!</span><br><br><span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> depending on what machine you&#x27;re using,</span><br><span class="hljs-comment"># you might not see a speedup when you go from two loops to one loop,</span><br><span class="hljs-comment"># and might even see a slow-down.</span><br><br><span class="hljs-comment"># my Output:</span><br><span class="hljs-comment"># Two loop version took 39.707868 seconds</span><br><span class="hljs-comment"># One loop version took 61.474561 seconds</span><br><span class="hljs-comment"># No loop version took 0.530087 seconds</span><br><span class="hljs-comment"># 说明：运行到one_loop时和Colab连接断开，一会后才继续恢复执行，所以时间有点离谱</span><br><span class="hljs-comment"># 不过跑前面的的代码块的时候one_loop的时间大概45秒左右（没记错的话）。</span><br></code></pre></td></tr></table></figure>
<h3 id="交叉验证">交叉验证</h3>
<p>我们已经实现了kNN分类器，但目前的k=5是随意设定的。我们将通过交叉验证取得最好的超参数值（k值）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python">num_folds = <span class="hljs-number">5</span><br>k_choices = [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">8</span>, <span class="hljs-number">10</span>, <span class="hljs-number">12</span>, <span class="hljs-number">15</span>, <span class="hljs-number">20</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>]<br><br>X_train_folds = []<br>y_train_folds = []<br><span class="hljs-comment">################################################################################</span><br><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span>                                                                        #</span><br><span class="hljs-comment"># Split up the training data into folds. After splitting, X_train_folds and    #</span><br><span class="hljs-comment"># y_train_folds should each be lists of length num_folds, where                #</span><br><span class="hljs-comment"># y_train_folds[i] is the label vector for the points in X_train_folds[i].     #</span><br><span class="hljs-comment"># Hint: Look up the numpy array_split function.                                #</span><br><span class="hljs-comment">################################################################################</span><br>X_train_folds = np.array_split(X_train, num_folds)<br>y_train_folds = np.array_split(y_train, num_folds)<br><br><span class="hljs-comment"># A dictionary holding the accuracies for different values of k that we find</span><br><span class="hljs-comment"># when running cross-validation. After running cross-validation,</span><br><span class="hljs-comment"># k_to_accuracies[k] should be a list of length num_folds giving the different</span><br><span class="hljs-comment"># accuracy values that we found when using that value of k.</span><br>k_to_accuracies = &#123;&#125;<br><br><br><span class="hljs-comment">################################################################################</span><br><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span>                                                                        #</span><br><span class="hljs-comment"># Perform k-fold cross validation to find the best value of k. For each        #</span><br><span class="hljs-comment"># possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #</span><br><span class="hljs-comment"># where in each case you use all but one of the folds as training data and the #</span><br><span class="hljs-comment"># last fold as a validation set. Store the accuracies for all fold and all     #</span><br><span class="hljs-comment"># values of k in the k_to_accuracies dictionary.                               #</span><br><span class="hljs-comment">################################################################################</span><br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> k_choices:<br>  k_to_accuracies[k] = []<br>  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_folds):<br>    train_X = np.concatenate([X_train_folds[j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_folds) <span class="hljs-keyword">if</span> j != i])<br>    train_y = np.concatenate([y_train_folds[j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_folds) <span class="hljs-keyword">if</span> j != i])<br>    test_X = X_train_folds[i]<br>    test_y = y_train_folds[i]<br>    classifier = KNearestNeighbor()<br>    classifier.train(train_X, train_y)<br>    test_y_pred = classifier.predict(X=test_X, k=k, num_loops=<span class="hljs-number">0</span>)<br>    num_correct = np.<span class="hljs-built_in">sum</span>(test_y_pred == test_y)<br>    accuracy = <span class="hljs-built_in">float</span>(num_correct) / <span class="hljs-built_in">len</span>(test_y)<br>    k_to_accuracies[k].append(accuracy)<br><br><span class="hljs-comment"># Print out the computed accuracies</span><br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(k_to_accuracies):<br>    <span class="hljs-keyword">for</span> accuracy <span class="hljs-keyword">in</span> k_to_accuracies[k]:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;k = %d, accuracy = %f&#x27;</span> % (k, accuracy))<br></code></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs output">k = 1, accuracy = 0.263000<br>k = 1, accuracy = 0.257000<br>k = 1, accuracy = 0.264000<br>k = 1, accuracy = 0.278000<br>k = 1, accuracy = 0.266000<br>k = 3, accuracy = 0.239000<br>k = 3, accuracy = 0.249000<br>k = 3, accuracy = 0.240000<br>k = 3, accuracy = 0.266000<br>k = 3, accuracy = 0.254000<br>k = 5, accuracy = 0.248000<br>k = 5, accuracy = 0.266000<br>k = 5, accuracy = 0.280000<br>k = 5, accuracy = 0.292000<br>k = 5, accuracy = 0.280000<br>k = 8, accuracy = 0.262000<br>k = 8, accuracy = 0.282000<br>k = 8, accuracy = 0.273000<br>k = 8, accuracy = 0.290000<br>k = 8, accuracy = 0.273000<br>k = 10, accuracy = 0.265000<br>k = 10, accuracy = 0.296000<br>k = 10, accuracy = 0.276000<br>k = 10, accuracy = 0.284000<br>k = 10, accuracy = 0.280000<br>k = 12, accuracy = 0.260000<br>k = 12, accuracy = 0.295000<br>k = 12, accuracy = 0.279000<br>k = 12, accuracy = 0.283000<br>k = 12, accuracy = 0.280000<br>k = 15, accuracy = 0.252000<br>k = 15, accuracy = 0.289000<br>k = 15, accuracy = 0.278000<br>k = 15, accuracy = 0.282000<br>k = 15, accuracy = 0.274000<br>k = 20, accuracy = 0.270000<br>k = 20, accuracy = 0.279000<br>k = 20, accuracy = 0.279000<br>k = 20, accuracy = 0.282000<br>k = 20, accuracy = 0.285000<br>k = 50, accuracy = 0.271000<br>k = 50, accuracy = 0.288000<br>k = 50, accuracy = 0.278000<br>k = 50, accuracy = 0.269000<br>k = 50, accuracy = 0.266000<br>k = 100, accuracy = 0.256000<br>k = 100, accuracy = 0.270000<br>k = 100, accuracy = 0.263000<br>k = 100, accuracy = 0.256000<br>k = 100, accuracy = 0.263000<br></code></pre></td></tr></table></figure>
<p>可视化一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># plot the raw observations</span><br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> k_choices:<br>    accuracies = k_to_accuracies[k]<br>    plt.scatter([k] * <span class="hljs-built_in">len</span>(accuracies), accuracies)<br><br><span class="hljs-comment"># plot the trend line with error bars that correspond to standard deviation</span><br>accuracies_mean = np.array([np.mean(v) <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(k_to_accuracies.items())])<br>accuracies_std = np.array([np.std(v) <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(k_to_accuracies.items())])<br>plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)<br>plt.title(<span class="hljs-string">&#x27;Cross-validation on k&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;k&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Cross-validation accuracy&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>
<figure>
<img src="/images/cs231n/knn-cross-val.png" srcset="/imgs/loading.gif" lazyload alt="Cross-validation on k" /><figcaption>Cross-validation on k</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Based on the cross-validation results above, choose the best value for k,</span><br><span class="hljs-comment"># retrain the classifier using all the training data, and test it on the test</span><br><span class="hljs-comment"># data. You should be able to get above 28% accuracy on the test data.</span><br>best_k = <span class="hljs-number">10</span><br><br>classifier = KNearestNeighbor()<br>classifier.train(X_train, y_train)<br>y_test_pred = classifier.predict(X_test, k=best_k)<br><br><span class="hljs-comment"># Compute and display the accuracy</span><br>num_correct = np.<span class="hljs-built_in">sum</span>(y_test_pred == y_test)<br>accuracy = <span class="hljs-built_in">float</span>(num_correct) / num_test<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Got %d / %d correct =&gt; accuracy: %f&#x27;</span> % (num_correct, num_test, accuracy))<br><br><span class="hljs-comment"># Output:</span><br><span class="hljs-comment"># Got 141 / 500 correct =&gt; accuracy: 0.282000</span><br></code></pre></td></tr></table></figure>
<p><strong>Inline Question 3</strong></p>
<p>Which of the following statements about <span class="math inline"><em>k</em></span>-Nearest Neighbor (<span class="math inline"><em>k</em></span>-NN) are true in a classification setting, and for all <span class="math inline"><em>k</em></span>? Select all that apply. 1. The decision boundary of the k-NN classifier is linear. 2. The training error of a 1-NN will always be lower than or equal to that of 5-NN. 3. The test error of a 1-NN will always be lower than that of a 5-NN. 4. The time needed to classify a test example with the k-NN classifier grows with the size of the training set. 5. None of the above.</p>
<p><span class="math inline">$\color{blue}{\textit Your Answer:}$</span> 2, 4</p>
<p><span class="math inline">$\color{blue}{\textit Your Explanation:}$</span> When k=1, each prediction is based on solely point, which may lead to overfitting, when increasing k, the classifier gain the ability of generalization, it perform on training may not as good as 1-NN. For k-NN, all computations are in prediction, so once test a example, it needs to calculate distances to all training points.</p>
<h2 id="q2-implement-a-softmax-classifier">Q2: Implement a Softmax classifier</h2>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" class="category-chain-item">计算机</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" class="print-no-link">#计算机视觉</a>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CS231n：Assignment1</div>
      <div>https://logicff.github.io/2025/11/14/cs231n-1/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>logicff</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年11月14日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - 非商业性使用">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/11/09/6.5840-2/" title="6.5840：Lab2 - Key/Value Server">
                        <span class="hidden-mobile">6.5840：Lab2 - Key/Value Server</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
